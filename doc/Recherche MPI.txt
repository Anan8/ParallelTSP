
Allgemein
Nachrichten werden in MPI ausgetauscht, indem den entsprechenden Operationen mitgeteilt wird, wo die Nachricht beginnt (address), aus wievielen Teilen sie besteht (count) und welchen Datentyp die Elemente besitzen (datatype). Dieses (address, count, datatype)-Modell durchzieht alle MPI-Funktionen, die etwas mit Senden oder Empfangen von Nachrichten zu tun haben.
Desweiteren haben alle solche Funktionen einen source-Parameter und/oder einen dest-Parameter, welche die Quelle und/oder das Ziel der Nachricht angeben. Daneben gibt es diverse Hilfsfunktionen, die das Senden und Empfangen von bestimmten Variablen einfacher gestalten. Zum Beispiel kann man neue Typen definieren und Prozesse zu Gruppen zusammenfassen


Für den Benutzer ist sowohl die Reihenfolge der Prozesse als auch deren Arbeitsgeschwindigkeit nicht vorherbestimmbar.
Die Header-Dateien sollten sich im include-Verzeichnis der Zielmaschine befinden. Ansonsten müssen die Pfade entweder in der umgebenden Shell gesetzt oder in mpicc (bzw. im entsprechenden Skript) angepaßt werden.


die Prozesse müssen mittels eines MPI Tools gestartet 
werden JUROPA: mpiexec

MPI muss vor der ersten Verwendung initialisiert werden

- Achtung: vor Initialisierung ist der Status des Programms undefiniert! nach Beenden ebenfalls
- Variablen und Funktionen im Programm dürfen nicht mit MPI_ oder PMPI_ beginnen.


//##########################################
#include <stdio.h>                    
#include <mpi.h>                      

main (int argc, char* argv[]) {

 int myrank;
 int size;

 MPI_Init(&argc, &argv);                   
 MPI_Comm_rank(MPI_COMM_WORLD, &myrank);    
 MPI_Comm_size(MPI_COMM_WORLD, &size);      

 printf("Hello World. I'm process %d of %d processes.", myrank, size);

 MPI_Finalize();
 exit(0);

}
//###############################################

- MPI_Init() initialisiert MPI
- mit MPI_Initialized lässt sich überprüfen ob MPI initialisiert wurde.
- MPI_Comm_rank die Nummer (rank) des Prozesses im Kommunikator. Ein Kommunikator ist in MPI ein Bereich von Prozessen, der bei einer Kommunikationsfunktion als Einheit angesprochen werden kann. MPI_COMM_WORLD ist der Kommunikator, der alle Prozesse beinhaltet.
- MPI_Comm-Size = Anzahl der Prozesse im Kommunikator (MPI_COMM_WORLD)
- MPI_Finalize beendet MPI (Muss am ende eines Programms von jedem Prozess aufgerufen werden. MPI_Finalized prüft ob MPI beendet wurde)

ACHTUNG: keinen Deadlock erzeugen. (Wenn z.B. mit MPI_Recv solange blockiert wird bis etwas empfangen wurde, aber kein MPI_Send abgefeuert wird)


- MPI stellt vier Varianten zur Verfügung, um Daten zu versenden, nämlich blockierend, gepuffert, synchronisiert und im "ready mode"
- Zu jeder Sende-Operation gehört eine Empfangsoperation.





BEISPIEL Senden einer Nachricht.
//########################################
#include <stdio.h>
#include <mpi.h>

main (int argc, char* argv[]) {

 int myrank; // beinhaltet die Nummer des Prozesses, auf dem diese Instanz des Programms läuft
 int size;   // beinhaltet die Anzahl der Prozesse insgesamt
 int from;                                 // wird den Vorgänger eines Prozesses beinhalten
 int to;                                   // wird den Nachfolger eines Prozesses beinhalten
 MPI_Status status;                        // eine Status-Variable, die hier ignoriert wird
 char message[8];                          // beinhaltet die Nachricht

 MPI_Init(&argc, &argv);                   // MPI initialisieren
 MPI_Comm_rank(MPI_COMM_WORLD, &myrank);   // Nummer des Prozesses holen, auf dem diese Instanz des Programms läuft
 MPI_Comm_size(MPI_COMM_WORLD, &size);     // Anzahl der Prozesse merken

 sprintf(message, "MESSAGE");

 if (myrank!=0) {                          // wenn diese Instanz nicht auf dem ersten Proozeß läuft
  from=(size+myrank-1) % size;             // Vorgänger bestimmen
  MPI_Recv (message,8,MPI_CHAR,from,0,MPI_COMM_WORLD,&status);
                                           // vom Vorgänger empfangen
  // Eigentlich müßte es heißen : Darauf warten, daß der Vorgänger eine Nachricht sendet
  
  printf("Process %d received message %s from process %d.\n", myrank, message, from);
 } 

 if (myrank!=(size-1)) {                   // wenn diese Instanz nicht auf dem letzten Prozeß läuft
  to=(myrank+1) % size;                    // Nachfolger bestimmen
  printf("Process %d is sending message %s to process %d.\n",myrank,message,to);
  MPI_Send (message,strlen(message)+1,MPI_CHAR,to,0,MPI_COMM_WORLD);
                                           // an den Nachfolger eine Nachricht schicken
 } 

 MPI_Finalize();                           // MPI beenden
 exit(0);

}
//##################################################

Damit wird das Wandern einer Nachricht durch alle Prozesse simuliert. Das funktioniert, da hier die Funktionen MPI_Send und MPI_Recv synchronisierend sind.



Ale Prozesse ansteuersn mit Broadcast
- MPI_Bcast(&num, 1, MPI_INT, 0, MPI_COMM_WORLD);



Wichtige Befehle

Parallel zum eigentlichen Programm ausführen
- MPI_Isend
- MPI_Ibsend
- MPI_Irsend
- MPI_Issend
Status von Prozessen herausfinden
- MPI_Test
- MPI_Testall
- MPI_Testany
- MPI_Testsome
Warten erzwingen um zu Synchronisieren
- MPI_Wait
- MPI_Waitall
- MPI_Waitany
- MPI_Waitsome




//################################################################
Ein Schönes Beispiel
/* Prozeß 0 spielt den Manager */

 if (rank == 0) {

  /* Daten vorbereiten */ 
  workers = size - 1;
  /*hier alles was wir senden möchten*/
  data = malloc(sizeof(int) * workers * len);
  request = malloc(sizeof(MPI_Request) * workers);
  

  for (i = 0; i < workers * len; ++i) {
   data[i] = i;
  }
    
  /* Daten zu den Arbeitern senden */
  for (i = 0; i < workers; ++i) {
   dest = i + 1;

   /* nichtblockierendes Senden verwenden */
   MPI_Isend(data + i * len, len, MPI_INT, dest, dest, MPI_COMM_WORLD, &request[i]);
   /* Hier wird an fünfter Stelle ein Tag-Parameter benutzt, der die Operation kennzeichnet.
      Dasselbe passiert beim Empfangen. */
  }

  /* warten, bis alle Daten versendet wurden */
  MPI_Waitall(workers, request, MPI_STATUSES_IGNORE);

  /* Ergebnisse erwarten */
  for (i = 0; i < workers; ++i) {
   source = i + 1;

   /* nichtblockierendes Empfangen */
   MPI_Irecv(sum + i, 1, MPI_INT, source, source, MPI_COMM_WORLD, &request[i]);
  }

  /* warten, bis alle Daten empfangen wurden */
  MPI_Waitall(workers, request, MPI_STATUSES_IGNORE);

  /###########
  /* Hier neue Population berechnen */
  //##########


  /* und aufrämen */
  free(data);
  free(sum);
  free(request);
 }

 /* Code für die Arbeiter */
 else {

  /* Behälter für Daten vorbereiten */
  data = malloc(sizeof(int) * len);
  mysum = 0;

  /* Daten vom Manager empfangen */
  MPI_Recv(data, len, MPI_INT, 0, rank, MPI_COMM_WORLD, MPI_STATUS_IGNORE);

  //##########
  /* hier die Route berechnen*/
  //##########
  

  /* und wieder zurück an den Manager senden */
  MPI_Send(&mysum, 1, MPI_INT, 0, rank, MPI_COMM_WORLD);

  /* und wieder aufrämen */
  free(data);
 }

 MPI_Finalize();
 return 0;
//##########################################################




Verteilen von Datenstrukturen
- MPI_Scatter
- MPI_Scatterv


Sammeln von Datenstrukturen
- MPI_Gather
- MPI_Gatherv



//##########verteilen und wieder einsammeln#################################################
//######Beispiel Summen Bildung########
#include "mpi.h"
#include <stdio.h>

#define ARRAYSIZE 16000000
#define MASTER 0

/* Behälter für Daten */
float data[ARRAYSIZE];

int main(int argc,char *argv[]) {

 int numtasks, taskid, rc, dest, source, offset;
 int i, j, tag1, tag2, chunksize; 

 float mysum, sum;
 float update(int myoffset, int chunk, int myid);

 MPI_Status status;

 /* MPI initialisieren */
 MPI_Init(&argc, &argv);
 MPI_Comm_size(MPI_COMM_WORLD, &numtasks);
 MPI_Comm_rank(MPI_COMM_WORLD,&taskid);

 /* Anzahl der Prozesse muß durch 4 teilbar sein */
 if (numtasks % 4 != 0) {
  printf("Exiting, number of tasks must be divisible by 4, it is currently %d.\n", numtasks);
  MPI_Abort(MPI_COMM_WORLD, rc);
  exit(0);
 }

 printf ("MPI task %d has started...\n", taskid);

 chunksize = (ARRAYSIZE / numtasks);
 tag2 = 1;
 tag1 = 2;

 /* Code des Managers */
 if (taskid == MASTER) {

 /* Daten vorbereiten */
 sum = 0;
 for(i=0; i < ARRAYSIZE; i++) {
  data[i] =  i * 1.0;
  sum = sum + data[i];
 }

 /* Daten auf alle Prozesse verteilen */
 offset = chunksize;
 for (dest=1; dest < numtasks; dest++) {
  MPI_Send(&offset, 1, MPI_INT, dest, tag1, MPI_COMM_WORLD);
  MPI_Send(&data[offset], chunksize, MPI_FLOAT, dest, tag2, MPI_COMM_WORLD);
  offset = offset + chunksize;
 }

 /* der Manager muß seinen Teil beitragen */
 offset = 0;
 mysum = update(offset, chunksize, taskid);

 /* warten auf die Ergebnisse der Arbeiter */
 for (i=1; i < numtasks; i++) {
  source = i;
  MPI_Recv(&offset, 1, MPI_INT, source, tag1, MPI_COMM_WORLD, &status);
  MPI_Recv(&data[offset], chunksize, MPI_FLOAT, source, tag2,
  MPI_COMM_WORLD, &status);
 }

 /* die einzelnen Summen der Arbeiter sammeln und aufaddieren */
 MPI_Reduce(&mysum, &sum, 1, MPI_FLOAT, MPI_SUM, MASTER, MPI_COMM_WORLD);

 printf("\nresults: \n");
 offset = 0;
 for (i=0; i < numtasks; i++) {
  for (j=0; j<5; j++) {
   printf("  %e",data[offset+j]);
  }
  printf("\n");
  offset = offset + chunksize;
 }
 printf("sum= %e\n",sum);

 }

 /* Code für Arbeiter */

 if (taskid > MASTER) {

  /* Daten vom Manager empfangen */
  source = MASTER;
  MPI_Recv(&offset, 1, MPI_INT, source, tag1, MPI_COMM_WORLD, &status);
  MPI_Recv(&data[offset], chunksize, MPI_FLOAT, source, tag2, MPI_COMM_WORLD, &status);

  /* aufaddieren
  mysum = update(offset, chunksize, taskid);

  /* und Daten zurückschicken */
  dest = MASTER;
  MPI_Send(&offset, 1, MPI_INT, dest, tag1, MPI_COMM_WORLD);
  MPI_Send(&data[offset], chunksize, MPI_FLOAT, MASTER, tag2, MPI_COMM_WORLD);

  /* an der Summenbildung teilnehmen */
  MPI_Reduce(&mysum, &sum, 1, MPI_FLOAT, MPI_SUM, MASTER, MPI_COMM_WORLD);

 }

 MPI_Finalize();

}

/* Summe der Daten eines einzelnen Prozesses berechnen */
float update(int myoffset, int chunk, int myid) {

 int i; 
 float mysum;

 mysum = 0;
 for(i=myoffset; i < myoffset + chunk; i++) {
  data[i] = data[i] + i * 1.0;
  mysum = mysum + data[i];
 }

 return(mysum);
}
//################################################################




Datentypen 
MPI kann weder Typ-Aliase (typedef) noch Zeiger (*) verschicken. Auch kann MPI nicht die zusammengesetzten Typen verarbeiten, die mit [] oder struct erstellt werden.



Zeitmessung
- MPI_Wtime();





Fehlerbehandlung
- MPI_WTime
- MPI_WTick
- MPI_Abort (im Notfall Abbruch wenn garnichts geht)

Standard Error Handling
- MPI_ERRORS_ARE_FATAL
- MPI_ERRORS_RETURN


in C++ ist es ein Struct

typedef struct { 
    int MPI_SOURCE;
    int MPI_TAG;
    int MPI_ERROR;
    int size;
    int reserved[2];
} MPI_Status;

Das Mitglied MPI_SOURCE gibt die Quelle an, die bei der Kommunikationsoperation beteiligt war, das Mitglied MPI_TAG gibt die Kennzeichnung (tag) der Nachricht zurück, die mit der Kommunikationsoperation behandelt worden ist. MPI_ERROR gibt den Fehler/Erfolg wieder, der bei dieser Nachricht aufgetreten ist. Das Mitglied size schließlich gibt die Größe der Nachricht an.

